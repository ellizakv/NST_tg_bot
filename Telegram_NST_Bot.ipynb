{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONcbtiZsnlrV/qN+ij/Szx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ellizakv/NST_tg_bot/blob/main/Telegram_NST_Bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#библиотека для телебота\n",
        "!pip install pytelegrambotapi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Iaw0oyxWh5y",
        "outputId": "750fb121-0355-445d-b727-7867433eef09"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytelegrambotapi in /usr/local/lib/python3.8/dist-packages (4.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from pytelegrambotapi) (2.25.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->pytelegrambotapi) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->pytelegrambotapi) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->pytelegrambotapi) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->pytelegrambotapi) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#загрузчик с google drive \n",
        "!pip install googledrivedownloader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMRXooZ6WmWM",
        "outputId": "bb89fa3c-0957-4a7d-d78e-ad38ac9acc9f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.8/dist-packages (0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eYmlhShrUfsv"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import copy\n",
        "import telebot\n",
        "import time \n",
        "\n",
        "\n",
        "bot = telebot.TeleBot('TOKEN') #адрес бота\n",
        "\n",
        "content_image = {} #картинка для обработки\n",
        "style_image = {} #картинки со стилем\n",
        "output_image = {} #результат\n",
        "\n",
        "@bot.message_handler(func=lambda message: True, content_types=['text'])\n",
        "def send_text(message):\n",
        "    user_id = message.chat.id\n",
        "    if ('/start') in message.text.lower():\n",
        "        bot.send_message(user_id, 'Привет, меня зовут NST. Я неизвестный художник. Мой главный талант - это изменять стиль изображений. Если хочешь проверить, то присылай мне первое изображение content.')\n",
        "\n",
        "\n",
        "@bot.message_handler(func=lambda message: True, content_types=['photo']) \n",
        "def photo(message):\n",
        "  user_id = message.chat.id\n",
        "  #if message.content_type == 'document':\n",
        "  #from pathlib import Path\n",
        "  #Path(f'files/{message.chat.id}/').mkdir(parents=True, exist_ok=True)\n",
        "  #if message.content_type == 'photo':\n",
        "   #    file_info = bot.get_file(message.photo[len(message.photo) - 1].file_id)\n",
        "   #    downloaded_file = bot.download_file(file_info.file_path)\n",
        "   #    #src = f'files/{message.chat.id}/' + file_info.file_path.replace('photos/', '')\n",
        "   #    with open(\"content_image.jpeg\", 'wb') as new_file:\n",
        "   #        new_file.write(downloaded_file)\n",
        "  #bot.send_message(message.from_user.id, 'Это контент. Пришли стиль') \n",
        "  if  user_id not in content_image and message.content_type == 'photo':\n",
        "    content_image[user_id] = message.photo[-1].file_id \n",
        "    file_info = bot.get_file(message.photo[len(message.photo) - 1].file_id)\n",
        "    downloaded_file = bot.download_file(file_info.file_path)\n",
        "    #src = f'files/{message.chat.id}/' + file_info.file_path.replace('photos/', '')\n",
        "    with open(\"content_image.jpeg\", 'wb') as new_file:\n",
        "      new_file.write(downloaded_file)\n",
        "    content_image[user_id] = message.photo[-1].file_id   \n",
        "    #time.sleep(20) \n",
        "    bot.send_message(message.chat.id, 'Принял! Присылай следующее изображение с картинкой, из которой я возьму стиль')  \n",
        "  else:\n",
        "    \t#если пользователь что-то отослал, записываем адрес второй картинки\n",
        "       style_image[user_id] = message.photo[-1].file_id\n",
        "       from pathlib import Path\n",
        "       Path(f'files/{message.chat.id}/').mkdir(parents=True, exist_ok=True)\n",
        "       if message.content_type == 'photo':\n",
        "          file_info = bot.get_file(message.photo[len(message.photo) - 1].file_id)\n",
        "          downloaded_file = bot.download_file(file_info.file_path)\n",
        "          #src = f'files/{message.chat.id}/' + file_info.file_path.replace('photos/', '')\n",
        "          with open(\"style_image.jpeg\", 'wb') as new_file:\n",
        "            new_file.write(downloaded_file)\n",
        "          bot.send_message(message.from_user.id, 'Дальше жди чуда. Я очень долгий, но рисую с душой!')\n"
        "          time.sleep(80)\n",
        "          StyleTransferModel()\n",
        "          # читаем полученный файл после преобразования                                                       \n",
        "          output_image = Image.open('/content/output_image.jpg')\n",
        "          #отправляем полученное изображение в чат\n",
        "          bot.send_photo(message.chat.id, output_image)\n",
        "          # bot.send_message(call.message.chat.id, emoji.emojize('Готово! Чтобы перезапустить бота нажми /start', use_aliases=True))\n",
        "          bot.send_message(message.chat.id, 'Было трудно, но я справился! Если хочешь попробовать снова, то пришли мне /start')\n",
        "\n",
        "          #bot.send_photo(message.chat.id, output_image)\n",
        "          #bot.send_message(call.message.chat.id, emoji.emojize('Готово! Чтобы перезапустить бота нажми /start', use_aliases=True))\n",
        "          #bot.send_message(message.chat.id, 'Готово! Чтобы перезапустить бота нажми /start')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def StyleTransferModel():\n",
        "  #GPU работаем с размером 512*512, либо CPU - 256*256\n",
        "  imsize = 512 if torch.cuda.is_available() else 256\n",
        "  \n",
        "  #обработка входящих изображений и преобразование в тензор\n",
        "  loader = transforms.Compose([\n",
        "    transforms.Resize(imsize),\n",
        "    transforms.CenterCrop(imsize),\n",
        "    transforms.ToTensor()])\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  \n",
        "  #обработка изображения \n",
        "  def image_loader(image_name):\n",
        "     image = Image.open(image_name)\n",
        "     image = loader(image).unsqueeze(0)\n",
        "     return image.to(device, torch.float)\n",
        "  \n",
        "  #подгружaем картинки style_img + content_img\n",
        "  content_img = image_loader(\"/content/content_image.jpeg\")\n",
        "  style_img = image_loader(\"/content/style_image.jpeg\")\n",
        "\n",
        "  \n",
        "  unloader = transforms.ToPILImage()  \n",
        "  plt.ion() \n",
        "  \n",
        "  #функция отрисовки изображения\n",
        "  def imshow(tensor, title=None):\n",
        "     image = tensor.cpu().clone()   \n",
        "     image = image.squeeze(0)      \n",
        "     image = unloader(image)\n",
        "     plt.imshow(image)\n",
        "     if title is not None:\n",
        "         plt.title(title)\n",
        "     plt.pause(0.001) \n",
        "  plt.figure()\n",
        "  imshow(content_img, title='Content Image')\n",
        "  \n",
        "  plt.figure()\n",
        "  imshow(style_img, title='Style Image')\n",
        "  #Content Loss\n",
        "  \n",
        "  class ContentLoss(nn.Module):\n",
        "         def __init__(self, target,):\n",
        "             super(ContentLoss, self).__init__()\n",
        "             #в явном виде пишем, чтобы таргет не изменялся\n",
        "             self.target = target.detach()\n",
        "             self.loss = F.mse_loss(self.target, self.target)\n",
        "\n",
        "         #input - картинка, которая передается на этот уровень\n",
        "         def forward(self, input):\n",
        "             self.loss = F.mse_loss(input, self.target)\n",
        "             return input\n",
        "  #векторизируем тензор, который вышел со сверточного слоя (чтобы перемножить вектора - нужны вектора, а не тензоры)\n",
        "  def gram_matrix(input):\n",
        "        #batch size=1\n",
        "        #h,w - размер feature map \n",
        "         batch_size, h, w, f_map_num = input.size()\n",
        "\n",
        "         features = input.view(batch_size * h, w * f_map_num)  \n",
        "\n",
        "         #перемножаем матрицы\n",
        "         G = torch.mm(features, features.t())\n",
        "\n",
        "         #нормализуем значения матрицы путем деления на количества элементов в каждой карте объектов\n",
        "         return G.div(batch_size * h * w * f_map_num)\n",
        "  #StyleLoss\n",
        "  class StyleLoss(nn.Module):\n",
        "    def __init__(self, target_feature):\n",
        "     super(StyleLoss, self).__init__()\n",
        "     #так же в явном виде указываем, что таргет (стиль в данном случае) не менять\n",
        "     self.target = gram_matrix(target_feature).detach()\n",
        "     self.loss = F.mse_loss(self.target, self.target)\n",
        "    def forward(self, input):\n",
        "      G = gram_matrix(input)\n",
        "      self.loss = F.mse_loss(G, self.target)\n",
        "      return input\n",
        "  #нормировка изображений из статьи про обучение сети\n",
        "  cnn_normalization_mean = torch.tensor([0.485, 0.456, 0.406]).to(device)\n",
        "  cnn_normalization_std = torch.tensor([0.229, 0.224, 0.225]).to(device)\n",
        "  \n",
        "  #нормализация изображений\n",
        "  class Normalization(nn.Module):\n",
        "        def __init__(self, mean, std):\n",
        "          super(Normalization, self).__init__()\n",
        "          self.mean = torch.tensor(mean).view(-1, 1, 1)\n",
        "          self.std = torch.tensor(std).view(-1, 1, 1)\n",
        "\n",
        "        def forward(self, img):\n",
        "          return (img - self.mean) / self.std\n",
        "\n",
        "  #уровни после которых считаем ошибку контента\n",
        "  content_layers_default = ['conv_4']\n",
        "  #уровни, почле которых считаем ошибку стиля\n",
        "  style_layers_default = ['conv_1', 'conv_2', 'conv_3', 'conv_4', 'conv_5']\n",
        "  \n",
        "  cnn = models.vgg19(pretrained=True).features.to(device).eval()\n",
        "  \n",
        "  #делаем свою новую модель из vgg19\n",
        "  def get_style_model_and_losses(cnn, normalization_mean, normalization_std,\n",
        "                                   style_img, content_img,\n",
        "                                   content_layers=content_layers_default,\n",
        "                                   style_layers=style_layers_default):\n",
        "         #копируем сеть, которую передали в функцию\n",
        "         cnn = copy.deepcopy(cnn)\n",
        "\n",
        "         #вставляем нормализующий уровень, т.е. чтобы vgg19 получила на вход такие же картинки, какие привыкла обрабатывать\n",
        "         #парамтры нормализации выше взяты их статьи про vgg19\n",
        "         normalization = Normalization(normalization_mean, normalization_std).to(device)\n",
        "\n",
        "         #вводим два листа для сохранения ошибок\n",
        "         content_losses = []\n",
        "         style_losses = []\n",
        "\n",
        "         #создаем модель, вносим первый уровень с нормализацией\n",
        "         model = nn.Sequential(normalization)\n",
        "\n",
        "         i = 0 \n",
        "         #идем по уровням, vgg19 (выше она названа cnn)\n",
        "         for layer in cnn.children():\n",
        "             #проверяем является ли слой экземпляром класса conv2d\n",
        "             if isinstance(layer, nn.Conv2d):\n",
        "                 i += 1\n",
        "                 #нумеруем сверточные слои\n",
        "                 name = 'conv_{}'.format(i)\n",
        "             elif isinstance(layer, nn.ReLU):\n",
        "                 name = 'relu_{}'.format(i)\n",
        "                 #пересоздаем, потому, что по другому не работает\n",
        "                 layer = nn.ReLU(inplace=False)\n",
        "             elif isinstance(layer, nn.MaxPool2d):\n",
        "                 name = 'pool_{}'.format(i)\n",
        "             elif isinstance(layer, nn.BatchNorm2d):\n",
        "                 name = 'bn_{}'.format(i)\n",
        "             else:\n",
        "                 raise RuntimeError('Unrecognized layer: {}'.format(layer.__class__.__name__))\n",
        "\n",
        "             #выше перебирали слои vgg19 и нумеровали их, ниже складываем их снова в модель\n",
        "             model.add_module(name, layer)\n",
        "   #проверяем имя слоя из списов выше (мы определили после каких слоев добавлять loss для контента и стиля)\n",
        "             #если слой из списка контент\n",
        "             if name in content_layers:\n",
        "                 #берем контент img\n",
        "                 target = model(content_img).detach()\n",
        "                 #считаем контент loss\n",
        "                 content_loss = ContentLoss(target)\n",
        "                 #добавляем в модель слой с вычислением контент-loss\n",
        "                 model.add_module(\"content_loss_{}\".format(i), content_loss)\n",
        "                 #саму ошибку отправляем в созданный выше лист\n",
        "                 content_losses.append(content_loss)\n",
        "\n",
        "             #аналогично для стиль-лосс\n",
        "             if name in style_layers:\n",
        "                 target_feature = model(style_img).detach()\n",
        "                 style_loss = StyleLoss(target_feature)\n",
        "                 model.add_module(\"style_loss_{}\".format(i), style_loss)\n",
        "                 style_losses.append(style_loss)\n",
        "\n",
        "         #обрезаем модель, т.е. все, что идет после последнего добавленного нами уровня\n",
        "         for i in range(len(model) - 1, -1, -1):\n",
        "             if isinstance(model[i], ContentLoss) or isinstance(model[i], StyleLoss):\n",
        "                 break\n",
        "\n",
        "         model = model[:(i + 1)]\n",
        "\n",
        "         #возвращаем модель, которая будет производить вычисления\n",
        "         #также возвращаем два листа лоссов\n",
        "         return model, style_losses, content_losses\n",
        "         \n",
        "  #устанавливаем оптимизатор, почему такой - из оригинальной статьи про transfer learning (перебрали разные - этот лучший)\n",
        "  def get_input_optimizer(input_img):\n",
        "        optimizer = optim.LBFGS([input_img.requires_grad_()])   \n",
        "        return optimizer\n",
        "  \n",
        "  style_weight=100000\n",
        "  #style_weight = 1e3 (разошелся)\n",
        "  #классическое обучение (num_steps=500 - количество эпох обучения)\n",
        "  #style_weight=100000, content_weight=1 (это alfa и betta из формулы про loss)\n",
        "  def run_style_transfer(cnn, normalization_mean, normalization_std,\n",
        "                         content_img, style_img, input_img, num_steps=500,\n",
        "                         style_weight=style_weight, content_weight=1):\n",
        "         \"\"\"Run the style transfer.\"\"\"\n",
        "         print('Building the style transfer model..')\n",
        "         #вызываем функцию, с нашей моделью и списками loss\n",
        "         model, style_losses, content_losses = get_style_model_and_losses(cnn,\n",
        "             normalization_mean, normalization_std, style_img, content_img)\n",
        "         #получаем оптимизатор\n",
        "         optimizer = get_input_optimizer(input_img)\n",
        "\n",
        "         print('Optimizing..')\n",
        "         #run в виде списка иначе все ломается\n",
        "         run = [0]\n",
        "         while run[0] <= num_steps:\n",
        "\n",
        "             #функция не вызывается, а подается в качестве агрумента для optimizer.step ниже\n",
        "             #описываем то, как считаем функцию потерь\n",
        "             def closure():\n",
        "                 #обрезаем тензор, чтобы цвета не вылетели за 0 и 1\n",
        "                 input_img.data.clamp_(0, 1)\n",
        "                 #обнуляем градиент\n",
        "                 optimizer.zero_grad()\n",
        "\n",
        "                 #пропускаем картинку через всю нейросеть, чтобы посчитались все лоссы\n",
        "                 model(input_img)\n",
        "\n",
        "                 #описываем функцию потреть, она у нас считается не стандартно\n",
        "                 style_score = 0\n",
        "                 content_score = 0\n",
        "\n",
        "                 #два лосса стиля и контента\n",
        "                 for sl in style_losses:\n",
        "                     style_score += sl.loss\n",
        "                 for cl in content_losses:\n",
        "                     content_score += cl.loss\n",
        "                \n",
        "                 #домножаем на веса\n",
        "                 style_score *= style_weight\n",
        "                 content_score *= content_weight\n",
        "\n",
        "                 #записываем итоговый лосс\n",
        "                 loss = style_score + content_score\n",
        "                 #запускаем обратное распростанение ошибки\n",
        "                 #при этом апдейтим только веса исходной картинки\n",
        "                 loss.backward()\n",
        "\n",
        "                 #отрисовка при обучении здачений функции потерь\n",
        "                 run[0] += 1\n",
        "                 if run[0] % 50 == 0:\n",
        "                     print(\"run {}:\".format(run))\n",
        "                     print('Style Loss : {:4f} Content Loss: {:4f}'.format(\n",
        "                         style_score.item(), content_score.item()))\n",
        "                     print()\n",
        "\n",
        "                 #возвращаем потери\n",
        "                 return style_score + content_score\n",
        "\n",
        "             #запускаем алгоритм апдейта весов картинки\n",
        "             optimizer.step(closure)\n",
        "\n",
        "         #обрезаем тензор, чтобы цвета не вылетели за 0 и 1\n",
        "         input_img.data.clamp_(0, 1)\n",
        "\n",
        "         #возвращаем картинку\n",
        "         return input_img\n",
        "\n",
        "  input_img = content_img.clone()\n",
        "  \n",
        "  plt.figure()\n",
        "  imshow(input_img, title='Input Image')\n",
        "  output = run_style_transfer(cnn, cnn_normalization_mean, cnn_normalization_std, content_img, style_img, input_img)\n",
        "  \n",
        "  #преобразовываем тензор в картинку\n",
        "  output_image = torch.squeeze(output)\n",
        "  output_image = transforms.ToPILImage()(output_image)\n",
        "  #сохраняем полученное изображение\n",
        "  output_image.save('output_image.jpg')\n",
        "  time.sleep(20)\n",
        "\n",
        "  plt.figure()\n",
        "  imshow(output, title='Output Image')\n",
        "  plt.ioff()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bot.stop_polling()"
      ],
      "metadata": {
        "id": "NwOrZLJqTCBj"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import telebot\n",
        "import time \n",
        "\n",
        "\n",
        "bot = telebot.TeleBot('TOKEN') #адрес бота\n"
      ],
      "metadata": {
        "id": "gmy59mzvpz7o"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bot.polling(none_stop=True, interval=0)"
      ],
      "metadata": {
        "id": "l0ls3TtEU9G_"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}
